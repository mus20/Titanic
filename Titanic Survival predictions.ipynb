{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: \n",
    "Cleaning the data:\n",
    "1. Replacing Nans in Cabin data with unknown.\n",
    "2. Extracting titles from names and compressing them into four categories:Mr,Mrs,Ms,Master\n",
    "3. Getting Deck data from cabin\n",
    "4. Dummy variables for Deck, titles, embarked columns\n",
    "5. Replacing Sex with a binary variables : 1 for Men and 0 for Women.\n",
    "6. Dropped rows with Nans - Age and Embarked\n",
    "\n",
    "Step 2:\n",
    "Feature Selection:\n",
    "1. Created a new variable Family_Count as the sum of Sibsp and Parch.\n",
    "2. Selected features that are only present in both train and test data.\n",
    "\n",
    "Step 3:\n",
    "Modelling \n",
    "1. Constructing a model using logicticregression function from sklearn on the train dataset.\n",
    "2. Implementing the model on the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train = pd.read_csv('train.csv')\n",
    "\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    if \" \" in big_string:\n",
    "        big_string = big_string.split(\" \")\n",
    "        \n",
    "    for substring in substrings:\n",
    "        if substring in big_string:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def replace_titles(x):\n",
    "    title=x['Titles']\n",
    "    if title in ['Dona.', 'Don.', 'Major.', 'Capt.', 'Jonkheer.', 'Rev.', 'Col.', 'Sir.']:\n",
    "        return 'Mr.'\n",
    "    elif title in ['the Countess.', 'Mme.']:\n",
    "        return 'Mrs.'\n",
    "    elif title in ['Mlle.', 'Ms.', 'Lady.']:\n",
    "        return 'Miss.'\n",
    "    elif title =='Dr.':\n",
    "        if x['Sex']=='Male':\n",
    "            return 'Mr.'\n",
    "        else:\n",
    "            return 'Mrs.'\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "def get_decks(df):\n",
    "    decks=[]\n",
    "    for val in df:\n",
    "        val_str = str(val)\n",
    "        decks.append(val_str[0])\n",
    "    unique_decks = list(set(decks))\n",
    "    return pd.Series(decks)\n",
    "\n",
    "def get_titles(df):\n",
    "    new_arr=[]\n",
    "    for row in df:\n",
    "        x = row.split(\", \")\n",
    "        y = x[1].split(\". \")[0]\n",
    "        z = y+'.'\n",
    "        new_arr.append(z)\n",
    "    return list(set(new_arr))\n",
    "\n",
    "train['Cabin']=train['Cabin'].fillna(\"Unknown\")\n",
    "\n",
    "train['Deck']=get_decks(train['Cabin'])\n",
    "train['Deck'].value_counts()\n",
    "\n",
    "titles = get_titles(train['Name'])\n",
    "\n",
    "train['Titles']=train['Name'].map(lambda x: substrings_in_string(x, titles))\n",
    "train['Titles']=train.apply(replace_titles, axis=1)\n",
    "train.loc[train['Titles'].isna(),'Titles'] = 'the Countess.'\n",
    "\n",
    "title_dummies = pd.get_dummies(train['Titles'])\n",
    "embarked_dummies = pd.get_dummies(train['Embarked'],prefix='Embarked')\n",
    "deck_dummies = pd.get_dummies(train['Deck'],prefix=\"Deck\")\n",
    "train = pd.concat([train,title_dummies,embarked_dummies,deck_dummies],axis=1)\n",
    "\n",
    "train['Age']=train['Age'].fillna(train['Age'].mean())\n",
    "train.isnull().sum()\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()\n",
    "test['Cabin']=test['Cabin'].fillna(\"Unknown\")\n",
    "\n",
    "test['Deck'] = get_decks(test['Cabin'])\n",
    "titles_test = get_titles(test['Name'])\n",
    "\n",
    "test['Titles']=test['Name'].map(lambda x: substrings_in_string(x, titles_test))\n",
    "test['Titles']=test.apply(replace_titles, axis=1)\n",
    "\n",
    "title_dummies_test = pd.get_dummies(test['Titles'])\n",
    "embarked_dummies_test = pd.get_dummies(test['Embarked'],prefix='Embarked')\n",
    "deck_dummies_test = pd.get_dummies(test['Deck'],prefix='Deck')\n",
    "test = pd.concat([test,title_dummies_test,embarked_dummies_test,deck_dummies_test],axis=1)\n",
    "\n",
    "test.isna().sum()\n",
    "\n",
    "test['Age']=test['Age'].fillna(test['Age'].mean())\n",
    "test['Fare']=test['Fare'].fillna(test['Fare'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Sex'] == 'male','Sex'] = 1\n",
    "train.loc[train['Sex'] == 'female','Sex'] = 0\n",
    "test.loc[test['Sex'] == 'male','Sex'] = 1\n",
    "test.loc[test['Sex'] == 'female','Sex'] = 0\n",
    "\n",
    "train['Family_Count'] = train['SibSp']+train['Parch']\n",
    "test['Family_Count'] = test['SibSp']+test['Parch']\n",
    "\n",
    "to_category = ['Survived','Pclass']\n",
    "for col in to_category:\n",
    "    train[col] = train[col].astype('category')\n",
    "\n",
    "test['Pclass'] = test['Pclass'].astype('category')\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39712918660287083\n",
      "0.36924803591470257\n",
      "0.835016835016835\n"
     ]
    }
   ],
   "source": [
    "features = ['Pclass', 'Sex', 'Age','Fare', 'Master.','Miss.', 'Mr.', 'Mrs.', 'Embarked_C',\n",
    "            'Embarked_Q', 'Embarked_S', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E',\n",
    "            'Deck_F', 'Deck_G', 'Deck_U','Family_Count']\n",
    "\n",
    "target = 'Survived'\n",
    "model = LogisticRegression()\n",
    "model.fit(train[features],train[target])\n",
    "predicted_probs_train = model.predict_proba(train[features])\n",
    "predicted_probs_test = model.predict_proba(test[features])\n",
    "\n",
    "survival_pred_train = pd.Series(np.asarray(np.round(predicted_probs_train[:,1]),dtype=int))\n",
    "survival_pred_test = pd.Series(np.asarray(np.round(predicted_probs_test[:,1]),dtype=int))\n",
    "\n",
    "accuracy_train = sum(survival_pred_train == train['Survived'])/len(survival_pred_train)\n",
    "print(sum(survival_pred_test)/len(survival_pred_test))\n",
    "print(sum(survival_pred_train)/len(survival_pred_train))\n",
    "print(accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_survival = pd.DataFrame([test['PassengerId'],survival_pred_test],index=['PassengerId','Survived'])\n",
    "test_survival = test_survival.transpose()\n",
    "test_survival = test_survival.set_index('PassengerId')\n",
    "test_survival.to_csv('test_survival.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
